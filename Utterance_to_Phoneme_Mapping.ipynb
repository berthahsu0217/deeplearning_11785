{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3p2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAuzXfODUs4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7AL9p7tVMUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urGVFyKuVNUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkirBrwJVUVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!mkdir root/.kaggle/\n",
        "!cp content/kaggle.json root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c 11-785-s20-hw3p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rztnIW8uX2yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVXazPJSY9am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p3ARjNW-tgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8NxcozdYjux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#loading dataset into numpy object\n",
        "train_data = np.load('wsj0_train', allow_pickle=True)\n",
        "train_labels = np.load('wsj0_train_merged_labels.npy', allow_pickle = True)\n",
        "val_data = np.load('wsj0_dev.npy', allow_pickle=True)\n",
        "val_labels = np.load('wsj0_dev_merged_labels.npy', allow_pickle=True)\n",
        "test_data = np.load('wsj0_test', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBMzYINacTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data.shape, train_labels.shape)\n",
        "print(val_data.shape, val_labels.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKWzJXnPdKVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import *\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6J7rHCyayTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, X, Y):\n",
        "        self.length = len(X)\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (torch.Tensor(self.X[index]), torch.Tensor(self.Y[index]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHlS0wnnd5KZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "#create dataloaders\n",
        "def pad_collate(batch):\n",
        "  (xx, yy) = zip(*batch)\n",
        "  x_lens = torch.LongTensor([len(x) for x in xx])\n",
        "  y_lens = torch.LongTensor([len(y) for y in yy])\n",
        "  xx_pad = pad_sequence(xx)\n",
        "  yy_pad = pad_sequence(yy, batch_first=True)\n",
        "  return xx_pad, yy_pad, x_lens, y_lens\n",
        "\n",
        "#adding context\n",
        "k = 12\n",
        "num_workers = 8 if cuda else 0 \n",
        "    \n",
        "# Training\n",
        "train_dataset = MyDataset(train_data, train_labels)\n",
        "train_loader_args = dict(shuffle=True, batch_size=64, num_workers=num_workers, pin_memory=True, collate_fn = pad_collate)\n",
        "train_loader = data.DataLoader(train_dataset, **train_loader_args)\n",
        "\n",
        "# Validating\n",
        "val_dataset = MyDataset(val_data, val_labels)\n",
        "val_loader_args = dict(shuffle=False, batch_size=64, num_workers=num_workers, pin_memory=True, collate_fn = pad_collate)\n",
        "val_loader = data.DataLoader(val_dataset, **val_loader_args)\n",
        "\n",
        "#delete to obtain more memory\n",
        "#del train_data\n",
        "#del train_labels\n",
        "#del val_data\n",
        "#del val_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKyOLfWLuOk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_vocab, out_vocab, hidden_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.cnn1 = nn.Conv1d(in_channels = in_vocab, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.batchnorm = nn.BatchNorm1d(128)\n",
        "        self.lstm = nn.LSTM(input_size = 256, hidden_size = hidden_size, num_layers = 4, bidirectional = True)\n",
        "        self.output = nn.Linear(hidden_size*2, out_vocab)\n",
        "    \n",
        "    def forward(self, X, lengths):\n",
        "        \n",
        "        X = self.cnn1(X.transpose(0,1).transpose(1,2))\n",
        "        X = self.batchnorm(X)\n",
        "        packed_X = pack_padded_sequence(X.transpose(1,2).transpose(0,1), lengths, enforce_sorted=False)\n",
        "        packed_out = self.lstm(packed_X)[0]\n",
        "        out, out_lens = pad_packed_sequence(packed_out)\n",
        "        # Log softmax after output layer is required since`nn.CTCLoss` expects log probabilities.\n",
        "        out = self.output(out).log_softmax(2)\n",
        "        return out, out_lens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lbl0NPw4zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(11785)\n",
        "model = Model(40,47,256)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "print(model)\n",
        "model.to(device)\n",
        "criterion = nn.CTCLoss(blank = 46)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 2, factor = 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQBk0TvuugG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (X, Y, X_lens, Y_lens) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "      out, out_lens = model(X, X_lens)\n",
        "      loss = criterion(out, Y, out_lens, Y_lens)\n",
        "      running_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    running_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    return running_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH4acqqIOhU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, val_loader, criterion, PHONEME_MAP):\n",
        "    \n",
        "    decoder = CTCBeamDecoder(PHONEME_MAP, beam_width=10, log_probs_input=True, blank_id=46)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      D = 0.0\n",
        "\n",
        "      for batch_idx, (X, Y, X_lens, Y_lens) in enumerate(val_loader):\n",
        "        \n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "        out, out_lens = model(X, X_lens)\n",
        "        predict_Y, _, _, predict_Y_lens = decoder.decode(out.transpose(0, 1), out_lens)\n",
        "        d = editDistance(Y, Y_lens, predict_Y, predict_Y_lens, PHONEME_MAP, decoder)\n",
        "        D += d\n",
        "        loss = criterion(out, Y, out_lens, Y_lens)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      running_loss /= len(val_loader)\n",
        "      total_size = len(val_loader)*64\n",
        "      D /= total_size\n",
        "      end_time = time.time()\n",
        "      print('Validation Loss: ', running_loss, 'Time: ', end_time - start_time, 's')\n",
        "      print(\"Average Edit Distance\", D)\n",
        "      return running_loss\n",
        "\n",
        "import stringdist\n",
        "\n",
        "def editDistance(Y, Y_lens, predict_Y, predict_Y_lens, PHONEME_MAP, decoder):\n",
        "\n",
        "    distance = 0\n",
        "    batch_size = Y.shape[0]\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      Y_seq = Y[i,:int(Y_lens[i])]\n",
        "      Y_pron = ''.join(PHONEME_MAP[int(i)] for i in Y_seq)\n",
        "\n",
        "      predict_Y_seq = predict_Y[i,0,:predict_Y_lens[i,0]]\n",
        "      predict_Y_pron = ''.join(PHONEME_MAP[i] for i in predict_Y_seq)\n",
        "      d = stringdist.levenshtein(Y_pron, predict_Y_pron)\n",
        "      distance += d\n",
        "    \n",
        "    return distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mhy8PZCxREo_",
        "colab": {}
      },
      "source": [
        "Train_loss = []\n",
        "Val_loss = []\n",
        "Val_acc = []\n",
        "\n",
        "for epoch in range(20):\n",
        "  train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "  val_loss = test_model(model, val_loader, criterion, PHONEME_MAP)\n",
        "  scheduler.step(val_loss)\n",
        "  print('='*20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCrdN_w1wrSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_loss = []\n",
        "Val_loss = []\n",
        "Val_acc = []\n",
        "\n",
        "for epoch in range(10):\n",
        "  train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "  val_loss = test_model(model, val_loader, criterion, PHONEME_MAP)\n",
        "  scheduler.step(val_loss)\n",
        "  print('='*20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKlhtXJw7Nne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(model, test_data, PHONEME_MAP):\n",
        "\n",
        "    df = pd.DataFrame(columns = [\"id\",\"Predicted\"])\n",
        "    ids = []\n",
        "    predicted = []\n",
        "\n",
        "    decoder = CTCBeamDecoder(PHONEME_MAP, beam_width=10, log_probs_input=True, blank_id=46)\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "      X = torch.Tensor(test_data[i])\n",
        "      length = len(X)\n",
        "      X = X.reshape((length,1,40))\n",
        "      X_lens = torch.Tensor([length])\n",
        "      \n",
        "      X = X.to(device)\n",
        "      out, out_lens = model(X, X_lens)\n",
        "      predict_Y, _, _, predict_Y_lens = decoder.decode(out.transpose(0, 1), out_lens)\n",
        "      predict_Y_seq = predict_Y[0,0,:predict_Y_lens[0,0]]\n",
        "      predict_Y_pron = ''.join(PHONEME_MAP[i] for i in predict_Y_seq)\n",
        "      ids.append(i)\n",
        "      predicted.append(predict_Y_pron)\n",
        "    \n",
        "    df['id'] = ids\n",
        "    df['Predicted'] = predicted\n",
        "    print(df)\n",
        "    saved = df.to_csv('result.csv', index = None, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsBQ8e2E-TNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_model(model, test_data, PHONEME_MAP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deEw3dTuYTmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PHONEME_LIST = [\n",
        "    \"+BREATH+\",\n",
        "    \"+COUGH+\",\n",
        "    \"+NOISE+\",\n",
        "    \"+SMACK+\",\n",
        "    \"+UH+\",\n",
        "    \"+UM+\",\n",
        "    \"AA\",\n",
        "    \"AE\",\n",
        "    \"AH\",\n",
        "    \"AO\",\n",
        "    \"AW\",\n",
        "    \"AY\",\n",
        "    \"B\",\n",
        "    \"CH\",\n",
        "    \"D\",\n",
        "    \"DH\",\n",
        "    \"EH\",\n",
        "    \"ER\",\n",
        "    \"EY\",\n",
        "    \"F\",\n",
        "    \"G\",\n",
        "    \"HH\",\n",
        "    \"IH\",\n",
        "    \"IY\",\n",
        "    \"JH\",\n",
        "    \"K\",\n",
        "    \"L\",\n",
        "    \"M\",\n",
        "    \"N\",\n",
        "    \"NG\",\n",
        "    \"OW\",\n",
        "    \"OY\",\n",
        "    \"P\",\n",
        "    \"R\",\n",
        "    \"S\",\n",
        "    \"SH\",\n",
        "    \"SIL\",\n",
        "    \"T\",\n",
        "    \"TH\",\n",
        "    \"UH\",\n",
        "    \"UW\",\n",
        "    \"V\",\n",
        "    \"W\",\n",
        "    \"Y\",\n",
        "    \"Z\",\n",
        "    \"ZH\"\n",
        "]\n",
        "\n",
        "PHONEME_MAP = [\n",
        "    '_',  # \"+BREATH+\"\n",
        "    '+',  # \"+COUGH+\"\n",
        "    '~',  # \"+NOISE+\"\n",
        "    '!',  # \"+SMACK+\"\n",
        "    '-',  # \"+UH+\"\n",
        "    '@',  # \"+UM+\"\n",
        "    'a',  # \"AA\"\n",
        "    'A',  # \"AE\"\n",
        "    'h',  # \"AH\"\n",
        "    'o',  # \"AO\"\n",
        "    'w',  # \"AW\"\n",
        "    'y',  # \"AY\"\n",
        "    'b',  # \"B\"\n",
        "    'c',  # \"CH\"\n",
        "    'd',  # \"D\"\n",
        "    'D',  # \"DH\"\n",
        "    'e',  # \"EH\"\n",
        "    'r',  # \"ER\"\n",
        "    'E',  # \"EY\"\n",
        "    'f',  # \"F\"\n",
        "    'g',  # \"G\"\n",
        "    'H',  # \"HH\"\n",
        "    'i',  # \"IH\"\n",
        "    'I',  # \"IY\"\n",
        "    'j',  # \"JH\"\n",
        "    'k',  # \"K\"\n",
        "    'l',  # \"L\"\n",
        "    'm',  # \"M\"\n",
        "    'n',  # \"N\"\n",
        "    'G',  # \"NG\"\n",
        "    'O',  # \"OW\"\n",
        "    'Y',  # \"OY\"\n",
        "    'p',  # \"P\"\n",
        "    'R',  # \"R\"\n",
        "    's',  # \"S\"\n",
        "    'S',  # \"SH\"\n",
        "    '.',  # \"SIL\"\n",
        "    't',  # \"T\"\n",
        "    'T',  # \"TH\"\n",
        "    'u',  # \"UH\"\n",
        "    'U',  # \"UW\"\n",
        "    'v',  # \"V\"\n",
        "    'W',  # \"W\"\n",
        "    '?',  # \"Y\"\n",
        "    'z',  # \"Z\"\n",
        "    'Z',  # \"ZH\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsOD5O-_JT7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(PHONEME_LIST), len(PHONEME_MAP))\n",
        "PHONEME_LIST.append(\"BLANK\")\n",
        "PHONEME_MAP.append(' ')\n",
        "print(len(PHONEME_LIST), len(PHONEME_MAP))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRY3bW7mqUSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install python-Levenshtein"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0MKccFBrNey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install StringDist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGPuc_ocBk1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EehDPE7wCw6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "decoder = CTCBeamDecoder([' ', 'A'], beam_width=4)\n",
        "probs = torch.Tensor([[0.2, 0.8], [0.8, 0.2]]).unsqueeze(0)\n",
        "print(probs.size())\n",
        "print(torch.LongTensor([2]))\n",
        "out, _, _, out_lens = decoder.decode(probs, torch.LongTensor([2]))\n",
        "print(out[0, 0, :out_lens[0, 0]])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
