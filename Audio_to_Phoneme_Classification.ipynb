{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7NjwuZHlLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gphfnnOyHmUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFnYDrwhIEC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRpNNqJyIHKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_a6wZiIOFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir root/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whypAPp_Hnzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp content/kaggle.json root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRC94ls8Hqaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c 11-785-s20-hw1p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuEqVBqMJHWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuRwq7kCHr77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BDuCPhRHtSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xYZXYUaKA18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading dataset into numpy object\n",
        "train_data = np.load('train.npy', allow_pickle=True)\n",
        "train_labels = np.load('train_labels.npy', allow_pickle = True)\n",
        "val_data = np.load('dev.npy', allow_pickle=True)\n",
        "val_labels = np.load('dev_labels.npy', allow_pickle=True)\n",
        "test_data = np.load('test.npy', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruFZnTQVKLHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data summary\n",
        "print(train_data.shape, train_labels.shape)\n",
        "print(val_data.shape, val_labels.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN9gqxm9JyZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, X, Y, k):\n",
        "\n",
        "        # X: data numpy object\n",
        "        # Y: label numpy object\n",
        "        # k: number of frames to be padded both sides of each frame\n",
        "        self.utter_len = dict()\n",
        "        self.X = dict()\n",
        "        self.Y = dict()\n",
        "        self.k = k\n",
        "        self.length = 0\n",
        "        pad = np.zeros((k,40))\n",
        "\n",
        "        #for each utterance\n",
        "        for i in range(len(X)):\n",
        "\n",
        "          #storing (start_idx, end_idx) of each utterance in utter_len dict\n",
        "          old_len = self.length\n",
        "          self.length += X[i].shape[0]\n",
        "          self.utter_len[i] = (old_len, self.length-1)\n",
        "\n",
        "          self.X[i] = torch.from_numpy(np.concatenate((pad, X[i], pad), axis = 0)).float()\n",
        "          self.Y[i] = torch.from_numpy(Y[i]).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #binary search for the right pair given an index      \n",
        "        left = 0\n",
        "        right = len(self.X)\n",
        "        while right-left > 0:\n",
        "          mid = int((left+right)/2)\n",
        "          #if index in the (mid)th row: return the vector\n",
        "          if self.utter_len[mid][0] <= index and self.utter_len[mid][1] >= index:\n",
        "            idx = index-self.utter_len[mid][0]\n",
        "            x = self.X[mid][idx:idx+2*self.k+1].reshape(-1)\n",
        "            y = self.Y[mid][idx]\n",
        "            return (x,y)\n",
        "          else:\n",
        "            if self.utter_len[mid][0] > index:\n",
        "              right = mid\n",
        "            if self.utter_len[mid][1] < index:\n",
        "              left = mid+1\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RiRelJzitfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dataloaders\n",
        "\n",
        "#adding context\n",
        "k = 12\n",
        "num_workers = 8 if cuda else 0 \n",
        "    \n",
        "# Training\n",
        "train_dataset = MyDataset(train_data, train_labels, k)\n",
        "\n",
        "train_loader_args = dict(shuffle=True, batch_size=256, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=64)\n",
        "train_loader = data.DataLoader(train_dataset, **train_loader_args)\n",
        "\n",
        "# Validating\n",
        "val_dataset = MyDataset(val_data, val_labels, k)\n",
        "\n",
        "val_loader_args = dict(shuffle=False, batch_size=256, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=1)\n",
        "val_loader = data.DataLoader(val_dataset, **val_loader_args)\n",
        "\n",
        "#delete to obtain more memory\n",
        "del train_data\n",
        "del train_labels\n",
        "del val_data\n",
        "del val_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwYsqPPkLQWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNetwork(torch.nn.Module):\n",
        "\n",
        "    #optimizing techniques\n",
        "    #increase n of layers 4 or 5\n",
        "    #decrease hidden neurons\n",
        "    #reduce lr on plateau torch\n",
        "    #adding drop out\n",
        "    #ensemble\n",
        "\n",
        "    def __init__(self, size_list):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        self.size_list = size_list\n",
        "        for i in range(len(size_list) - 2):\n",
        "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.BatchNorm1d(size_list[i+1]))\n",
        "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input_val):\n",
        "        return self.net(input_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JylWYVV7L-wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating model\n",
        "n = (2*k+1)*40\n",
        "model = MyNetwork([n, 2048, 1024, 1000, 512, 256, 138])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 2, factor = 0.1)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us9I0qnibPl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    start_time = time.time()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.to(device)\n",
        "        target = target.to(device) # all data & model on same device\n",
        "\n",
        "        outputs = model(data)\n",
        "        \n",
        "        loss = criterion(outputs, target)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    return running_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey06Oj17baa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, val_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):   \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += target.size(0)\n",
        "            correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, target).detach()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "\n",
        "        running_loss /= len(val_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        print('Testing Loss: ', running_loss)\n",
        "        print('Testing Accuracy: ', acc, '%')\n",
        "        return running_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yVkN7ErMVJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start training for 30 epochs\n",
        "n_epochs = 30\n",
        "Train_loss = []\n",
        "Val_loss = []\n",
        "Val_acc = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_acc = test_model(model, val_loader, criterion)\n",
        "    Train_loss.append(train_loss)\n",
        "    Val_loss.append(val_loss)\n",
        "    Val_acc.append(val_acc)\n",
        "    scheduler.step(val_loss)\n",
        "    print('='*20)\n",
        "    if val_acc > 63.0:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU9XyEWCuWw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, X, k):\n",
        "\n",
        "        self.utter_len = dict()\n",
        "        self.X = dict()\n",
        "        self.k = k\n",
        "        self.length = 0\n",
        "        pad = np.zeros((k,40))\n",
        "\n",
        "        #for each utterance\n",
        "        for i in range(len(X)):\n",
        "\n",
        "          #storing (start_idx, end_idx) of each utterance in utter_len dict\n",
        "          old_len = self.length\n",
        "          self.length += X[i].shape[0]\n",
        "          self.utter_len[i] = (old_len, self.length-1)\n",
        "\n",
        "          self.X[i] = torch.from_numpy(np.concatenate((pad, X[i], pad), axis = 0)).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #binary search for the right pair given an index      \n",
        "        left = 0\n",
        "        right = len(self.X)\n",
        "        while right-left > 0:\n",
        "          mid = int((left+right)/2)\n",
        "          #if index in the (mid)th row: return the vector\n",
        "          if self.utter_len[mid][0] <= index and self.utter_len[mid][1] >= index:\n",
        "            idx = index-self.utter_len[mid][0]\n",
        "            x = self.X[mid][idx:idx+2*self.k+1].reshape(-1)\n",
        "            return x\n",
        "          else:\n",
        "            if self.utter_len[mid][0] > index:\n",
        "              right = mid\n",
        "            if self.utter_len[mid][1] < index:\n",
        "              left = mid+1\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygE2XBmovyb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = TestDataset(test_data, k)\n",
        "\n",
        "test_loader_args = dict(shuffle=False, batch_size=256, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=1)\n",
        "                    \n",
        "test_loader = data.DataLoader(test_dataset, **test_loader_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TFiEFA1wD2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(model, test_loader):\n",
        "\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        for batch_idx, data in enumerate(test_loader):   \n",
        "            data = data.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            results.append(predicted)\n",
        "      \n",
        "    ans = pd.DataFrame(columns=[\"id\", \"label\"])\n",
        "    idx = 0\n",
        "    for i in range(len(results)):\n",
        "      for j, label in enumerate(results[i]):\n",
        "        ans = ans.append({'id': idx, 'label':label.item()}, ignore_index=True)\n",
        "        idx += 1\n",
        "\n",
        "    ans_csv = ans.to_csv('result.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n",
        "    print(ans)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SjBqxaYw6DO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use trained model to predict on test data\n",
        "predict_model(model, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVOo4oDw3muL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('result.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}