{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition_Verification_MobileNetV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPbWYAXmLwaE",
        "colab_type": "text"
      },
      "source": [
        "1. Download data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__iG03d56nAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ip59gm6r3cw6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f0b5130a-73c5-44d4-d70e-d045136adb4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayodeUJQ7IAV",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "f72eb354-8989-49ee-b9b5-7227fd9beae7"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4bbdc9b5-1c31-46c9-b9da-39ea60fb2312\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4bbdc9b5-1c31-46c9-b9da-39ea60fb2312\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZaXRQlt7N2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "66cf6d35-3fc9-4fef-8698-429837964ef9"
      },
      "source": [
        "%cd ..\n",
        "!mkdir root/.kaggle/\n",
        "!cp content/kaggle.json root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c 11-785-s20-hw2p2-classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading 11-785-hw2p2-s20.tgz.zip to /\n",
            " 99% 585M/589M [00:07<00:00, 49.7MB/s]\n",
            "100% 589M/589M [00:07<00:00, 77.8MB/s]\n",
            "Downloading hw2p2_classification_sample_submission.csv to /\n",
            "  0% 0.00/53.9k [00:00<?, ?B/s]\n",
            "100% 53.9k/53.9k [00:00<00:00, 55.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odDbe0Dn9ZaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "c61541ac-1a85-46a7-af67-679043666a10"
      },
      "source": [
        "!unzip 11-785-hw2p2-s20.tgz.zip\n",
        "!tar zxvf 11-785-hw2p2-s20.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  11-785-hw2p2-s20.tgz.zip\n",
            "  inflating: 11-785-hw2p2-s20.tgz    \n",
            "._11-785hw2p2-s20\n",
            "11-785hw2p2-s20/\n",
            "11-785hw2p2-s20/._validation_verification.zip\n",
            "11-785hw2p2-s20/validation_verification.zip\n",
            "11-785hw2p2-s20/._test_classification.zip\n",
            "11-785hw2p2-s20/test_classification.zip\n",
            "11-785hw2p2-s20/._validation_classification.zip\n",
            "11-785hw2p2-s20/validation_classification.zip\n",
            "11-785hw2p2-s20/._validation_trials_verification.txt\n",
            "11-785hw2p2-s20/validation_trials_verification.txt\n",
            "11-785hw2p2-s20/test_trials_verification_student.txt\n",
            "11-785hw2p2-s20/._test_order_classification.txt\n",
            "11-785hw2p2-s20/test_order_classification.txt\n",
            "11-785hw2p2-s20/._test_verification.zip\n",
            "11-785hw2p2-s20/test_verification.zip\n",
            "11-785hw2p2-s20/._train_data.zip\n",
            "11-785hw2p2-s20/train_data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-1Px0Cc-FE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd 11-785hw2p2-s20\n",
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Hd7Q5e5tok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ba707f31-71bc-483d-ab84-b7fd08b29c37"
      },
      "source": [
        "%cd 11-785hw2p2-s20\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '11-785hw2p2-s20'\n",
            "/11-785hw2p2-s20\n",
            "__MACOSX\t\t\t      train_data\n",
            "test_classification\t\t      train_data.zip\n",
            "test_classification.zip\t\t      validation_classification\n",
            "test_order_classification.txt\t      validation_classification.zip\n",
            "test_trials_verification_student.txt  validation_trials_verification.txt\n",
            "test_verification\t\t      validation_verification\n",
            "test_verification.zip\t\t      validation_verification.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegaQmmM-l2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7c2e69b5-725b-466f-883b-a1b28ac54775"
      },
      "source": [
        "%cd train_data/large\n",
        "!ls -1 | wc -l\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/11-785hw2p2-s20/train_data/large\n",
            "2000\n",
            "/11-785hw2p2-s20/train_data\n",
            "/11-785hw2p2-s20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHwLXwvZ6Uwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4831b14d-29e3-4da9-b686-011569fefc35"
      },
      "source": [
        "%cd train_data/medium\n",
        "!ls -1 | wc -l\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/11-785hw2p2-s20/train_data/medium\n",
            "2300\n",
            "/11-785hw2p2-s20/train_data\n",
            "/11-785hw2p2-s20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cz0BmlHMKpe",
        "colab_type": "text"
      },
      "source": [
        "2. Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b045dhzf1mBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e409cfb6-93ff-433d-997e-108460614f78"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd, nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2F0Rv9S2hG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_workers = 8\n",
        "\n",
        "data_transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.ImageFolder(root='train_data/medium/', transform=data_transform)\n",
        "val_data = datasets.ImageFolder(root='validation_classification/medium/', transform=data_transform)\n",
        "    \n",
        "# Training\n",
        "train_loader_args = dict(shuffle=True, batch_size=256, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=64)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, **train_loader_args) \n",
        "\n",
        "# Validating\n",
        "val_loader_args = dict(shuffle=False, batch_size=256, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=1)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, **val_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FssPvvK5Mdg9",
        "colab_type": "text"
      },
      "source": [
        "3. MobileNetV2 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsC6HnpGiCGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Sequential):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, s, k=3):\n",
        "        \n",
        "        super(CNN, self).__init__(\n",
        "            nn.Conv2d(c_in, c_out, k, s, 1, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "    \n",
        "class DepthwiseCNN(nn.Sequential):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, s, k=3):\n",
        "        \n",
        "        super(DepthwiseCNN, self).__init__(\n",
        "            nn.Conv2d(c_in, c_out, k, s, 1, groups=c_out, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "        \n",
        "class Expansion(nn.Sequential):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, k=1, s=1):\n",
        "        \n",
        "        super(Expansion, self).__init__(\n",
        "            nn.Conv2d(c_in, c_out, k, s, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "class Projection(nn.Sequential):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, k=1, s=1):\n",
        "        \n",
        "        super(Projection, self).__init__(\n",
        "            nn.Conv2d(c_in, c_out, k, s, bias=False),\n",
        "            nn.BatchNorm2d(c_out)\n",
        "        )\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, s, t):\n",
        "        \n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.invertedResidual = (c_in == c_out) and (s == 1)\n",
        "        \n",
        "        hidden = t*c_in\n",
        "        self.layers = []\n",
        "        self.layers.append(Expansion(c_in, hidden))\n",
        "        self.layers.append(DepthwiseCNN(hidden, hidden, s))\n",
        "        self.layers.append(Projection(hidden, c_out))\n",
        "        self.layers = nn.Sequential(*self.layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.invertedResidual:\n",
        "            return x + self.layers(x)\n",
        "        else:\n",
        "            return self.layers(x)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhW2KrqIhdU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MobileNetV2(nn.Module):\n",
        "    \n",
        "    def __init__(self, params):\n",
        "        \n",
        "        super(MobileNetV2, self).__init__()\n",
        "\n",
        "        self.layers = []\n",
        "\n",
        "        c_in = 3\n",
        "        for b in range(len(params)):\n",
        "            t, c_out, n, s = params[b]\n",
        "            if t is None:\n",
        "                self.layers.append(CNN(c_in, c_out, s))\n",
        "                c_in = c_out\n",
        "            else:\n",
        "                for i in range(n):\n",
        "                    if i == 0:\n",
        "                        self.layers.append(BottleNeck(c_in, c_out, s, t))\n",
        "                    else:\n",
        "                        self.layers.append(BottleNeck(c_in, c_out, 1, t))\n",
        "                    c_in = c_out\n",
        "\n",
        "        self.layers.append(nn.AvgPool2d(8))\n",
        "        self.layers.append(nn.Flatten())\n",
        "\n",
        "        self.layers.append(nn.Linear(c_in, 1000))\n",
        "        self.layers.append(nn.BatchNorm1d(1000))\n",
        "        self.layers.append(nn.ReLU(inplace = True))\n",
        "\n",
        "        self.layers = nn.Sequential(*self.layers)\n",
        "        \n",
        "        self.fc1 = nn.Linear(1000, 2300)\n",
        "        self.fc2 = nn.Linear(1000, 60)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        label = self.fc1(x)\n",
        "        embedding = self.fc2(x)\n",
        "        return label, embedding\n",
        "        \n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_normal_(m.weight.data)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgniyuhb6i6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40d4af99-622f-4b33-d676-e24582dc866d"
      },
      "source": [
        "# save only model parameters\n",
        "#PATH = \"./classifier_v2.pt\"\n",
        "#torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# load a saved model parameters\n",
        "model_save_name = 'classifier_v2.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "## Less optimised approaches ->\n",
        "# saving the entire model\n",
        "#torch.save(model, PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1kgYJCHM4io",
        "colab_type": "text"
      },
      "source": [
        "4. Construct a model object with custom hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMpFypI56iTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = [(None,32,1,1), \n",
        "          (1,16,1,1), \n",
        "          (3,24,2,2), \n",
        "          (3,32,3,1), \n",
        "          (3,64,4,2), \n",
        "          (3,96,3,1),\n",
        "          (3,160,3,1), \n",
        "          (3,320,1,1),\n",
        "          (None,1280,1,1)\n",
        "          ]\n",
        "\n",
        "#creating model\n",
        "model = MobileNetV2(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a-vDrPAdv8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c5cec8c-eebe-4fa6-fb57-5bd155320c9b"
      },
      "source": [
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (layers): Sequential(\n",
              "    (0): CNN(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (13): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (14): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(288, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (15): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (16): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (17): BottleNeck(\n",
              "      (layers): Sequential(\n",
              "        (0): Expansion(\n",
              "          (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): DepthwiseCNN(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Projection(\n",
              "          (0): Conv2d(480, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (18): CNN(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (19): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "    (20): Flatten()\n",
              "    (21): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "    (22): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (23): ReLU(inplace=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=1000, out_features=2300, bias=True)\n",
              "  (fc2): Linear(in_features=1000, out_features=60, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOz_fSETNpB5",
        "colab_type": "text"
      },
      "source": [
        "5. Train and validate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjTwmbVhip8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "#optimizer = optim.Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 2, factor = 0.8) #0.1\n",
        "#scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9, last_epoch=-1)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk67VX8ESbTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "    \n",
        "    start_time = time.time()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.to(device)\n",
        "        target = target.to(device) # all data & model on same device\n",
        "\n",
        "        outputs, embedding = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_predictions += target.size(0)\n",
        "        correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "        loss = criterion(outputs, target)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #if batch_idx % 100 == 0:\n",
        "          #print(batch_idx)\n",
        "        \n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    acc = (correct_predictions/total_predictions)*100.0\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    print('Training Accuracy: ', acc, '%')\n",
        "    return running_loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pfASF3uSf84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, val_loader, criterion):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(val_loader):   \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            outputs, embedding = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += target.size(0)\n",
        "            correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, target).detach()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "          \n",
        "        running_loss /= len(val_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        print('Testing Loss: ', running_loss)\n",
        "        print('Testing Accuracy: ', acc, '%')\n",
        "        return running_loss, acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTtxlMtqOGUb",
        "colab_type": "text"
      },
      "source": [
        "Some experimentation before ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Hgn8PhZ_Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.0045, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "#scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9, last_epoch=-1)\n",
        "#optimizer = optim.Adam(model.parameters())\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 1, factor = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_Fa8S1PaF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "outputId": "28c9553f-029c-42cc-8f18-4781325ebfc4"
      },
      "source": [
        "#start training for 10 more epochs (already trained with ~20 epochs)\n",
        "n_epochs = 10\n",
        "Train_loss = []\n",
        "Train_acc = []\n",
        "Val_loss = []\n",
        "Val_acc = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_acc = test_model(model, val_loader, criterion)\n",
        "    Train_loss.append(train_loss)\n",
        "    Train_acc.append(train_acc)\n",
        "    Val_loss.append(val_loss)\n",
        "    Val_acc.append(val_acc)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "      print('stored')\n",
        "      model_save_name = 'classifier_v2.pt'\n",
        "      path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "      torch.save(model.state_dict(), path)\n",
        "      best_acc = val_acc\n",
        "    \n",
        "    print('='*20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss:  0.30360123537397327 Time:  442.3075969219208 s\n",
            "Training Accuracy:  97.54535337010661 %\n",
            "Testing Loss:  1.2104858954747517\n",
            "Testing Accuracy:  75.71739130434783 %\n",
            "stored\n",
            "====================\n",
            "Training Loss:  0.28262762768497945 Time:  442.8721146583557 s\n",
            "Training Accuracy:  98.08941136403719 %\n",
            "Testing Loss:  1.2057682077089946\n",
            "Testing Accuracy:  75.71739130434783 %\n",
            "====================\n",
            "Training Loss:  0.2750187512640267 Time:  443.0605854988098 s\n",
            "Training Accuracy:  98.31382160298242 %\n",
            "Testing Loss:  1.2184726397196453\n",
            "Testing Accuracy:  75.26086956521739 %\n",
            "====================\n",
            "Training Loss:  0.2694927827498016 Time:  442.3762104511261 s\n",
            "Training Accuracy:  98.4848355845309 %\n",
            "Testing Loss:  1.2372204661369324\n",
            "Testing Accuracy:  75.08695652173914 %\n",
            "====================\n",
            "Training Loss:  0.22765936850480836 Time:  442.39450788497925 s\n",
            "Training Accuracy:  99.06355857472131 %\n",
            "Testing Loss:  1.1979770925309923\n",
            "Testing Accuracy:  75.3695652173913 %\n",
            "====================\n",
            "Training Loss:  0.2206126107494457 Time:  442.90203499794006 s\n",
            "Training Accuracy:  99.18604156150604 %\n",
            "Testing Loss:  1.2114894092082977\n",
            "Testing Accuracy:  75.41304347826086 %\n",
            "====================\n",
            "Training Loss:  0.21738311464191967 Time:  442.5248694419861 s\n",
            "Training Accuracy:  99.27519749925501 %\n",
            "Testing Loss:  1.2158603171507518\n",
            "Testing Accuracy:  75.60869565217392 %\n",
            "====================\n",
            "Training Loss:  0.1994911956033701 Time:  442.2956876754761 s\n",
            "Training Accuracy:  99.4305210088122 %\n",
            "Testing Loss:  1.2060458593898349\n",
            "Testing Accuracy:  75.43478260869566 %\n",
            "====================\n",
            "Training Loss:  0.19684823990276415 Time:  441.9493863582611 s\n",
            "Training Accuracy:  99.47430837250883 %\n",
            "Testing Loss:  1.2093939118915134\n",
            "Testing Accuracy:  75.78260869565217 %\n",
            "stored\n",
            "====================\n",
            "Training Loss:  0.1883078125464367 Time:  442.2763104438782 s\n",
            "Training Accuracy:  99.5517876799387 %\n",
            "Testing Loss:  1.2078617182042863\n",
            "Testing Accuracy:  75.69565217391305 %\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49OlLWfyau8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test_order_classification.txt') as file:\n",
        "     orders = [line.strip() for line in file]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3cFPMyo3woCl",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, order_path):\n",
        "\n",
        "        self.data_path = data_path\n",
        "        with open(order_path) as file:\n",
        "          self.orders = [line.strip() for line in file]\n",
        "        self.length = len(orders)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = Image.open(self.data_path + \"/\"+ self.orders[index])\n",
        "        array = data_transform(img)\n",
        "        return array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqpYcVGNwoSd",
        "colab_type": "text"
      },
      "source": [
        "6. Use the model to predict on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02nfD645cvmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MyDataset('test_classification/medium','test_order_classification.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UfSrDbSf5A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=1)\n",
        "\n",
        "test_loader = data.DataLoader(test_data, **test_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Jdn296gSjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model(model, test_loader, orders, labels):\n",
        "\n",
        "    embedding_map = dict()\n",
        "    results = []\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        for batch_idx, data in enumerate(test_loader):   \n",
        "            data = data.to(device)\n",
        "            #print(data.shape)\n",
        "            outputs, embedding = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            results.append(predicted)\n",
        "            embeddings.append(embedding)\n",
        "      \n",
        "    ans = pd.DataFrame(columns=[\"Id\", \"Category\"])\n",
        "    idx = 0\n",
        "    for i in range(len(results)):\n",
        "      for j, label in enumerate(results[i]):\n",
        "        ans = ans.append({'Id': orders[idx], 'Category':labels[label.item()]}, ignore_index=True)\n",
        "        embedding_map[orders[idx]] = embeddings[idx]\n",
        "        idx += 1\n",
        "\n",
        "    ans_csv = ans.to_csv('result.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n",
        "    print(ans)\n",
        "    return embedding_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwT8aCyAgZ36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "f2ed29e6-0f6a-46b7-8fb8-fa937c4cad3f"
      },
      "source": [
        "#use trained model to predict on test data\n",
        "results = predict_model(model, test_loader, orders, train_data.classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Id Category\n",
            "0     5000.jpg     1631\n",
            "1     5001.jpg      908\n",
            "2     5002.jpg      189\n",
            "3     5003.jpg     1359\n",
            "4     5004.jpg      164\n",
            "...        ...      ...\n",
            "4595  9595.jpg     2036\n",
            "4596  9596.jpg      683\n",
            "4597  9597.jpg      482\n",
            "4598  9598.jpg     1881\n",
            "4599  9599.jpg      727\n",
            "\n",
            "[4600 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QTOoRRPhS6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkt6rsBz2x9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, order_path):\n",
        "\n",
        "        self.data_path = data_path\n",
        "        with open(order_path) as file:\n",
        "          self.orders = [line.strip() for line in file]\n",
        "        self.length = len(self.orders)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        imgs = self.orders[index].split(' ')\n",
        "        img1 = Image.open(self.data_path + \"/\"+ imgs[0])\n",
        "        img2 = Image.open(self.data_path + \"/\"+ imgs[1])\n",
        "\n",
        "        trans =  transforms.ToTensor()\n",
        "        array1 = trans(img1)\n",
        "        array2 = trans(img2)\n",
        "\n",
        "        return array1, array2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3slx-qQ4Bd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MyDataset('test_verification/','test_trials_verification_student.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD09kYND4Vm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader_args = dict(shuffle=False, batch_size=256, num_workers=num_workers, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=1)\n",
        "\n",
        "test_loader = data.DataLoader(test_data, **test_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ-3jnsL6FsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "873f9833-956e-4bf1-8866-e13a93ce79c8"
      },
      "source": [
        "with open('test_trials_verification_student.txt') as file:\n",
        "     Vorders = [line.strip() for line in file]\n",
        "  \n",
        "print(Vorders[0].split(' '))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['262615.jpg', '207587.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6fwuaBNIRgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f7ce8ce1-22c7-497b-9c0e-8d9cba3eab0e"
      },
      "source": [
        "%cd test_verification\n",
        "!ls -1 | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/11-785hw2p2-s20/test_verification\n",
            "169392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ebG22Baexrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, array):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    array = array.to(device)\n",
        "    label, embedding = model(array)\n",
        "    return label.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ4cu9lv6K0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "6262d171-0b33-465b-fa35-7384075c3d64"
      },
      "source": [
        "#trials = []\n",
        "scores = []\n",
        "\n",
        "for idx, tup in enumerate(test_loader):\n",
        "\n",
        "    #imgs = Vorders[idx].split(' ')\n",
        "    arr1, arr2 = tup\n",
        "\n",
        "    embed1 = train_model(model, arr1)\n",
        "    embed2 = train_model(model, arr2)\n",
        "\n",
        "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
        "    score = cos(embed1, embed2)\n",
        "    score = score.flatten()\n",
        "    scores.extend(score.tolist())\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(idx)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_4xqoLGrhQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trials = [Vorders[i] for i in range(len(Vorders))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lckEAzDrpzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8013942a-b057-4016-af20-50937af88cc9"
      },
      "source": [
        "print(len(scores))\n",
        "print(len(trials))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "899965\n",
            "899965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Doyyi7gQxZKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b3711b70-85ca-46c9-8a02-4c9b91315aa6"
      },
      "source": [
        "df1 = pd.DataFrame(trials)\n",
        "df2 = pd.DataFrame(scores)\n",
        "df = pd.concat([df1, df2], axis = 1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262615.jpg 207587.jpg</td>\n",
              "      <td>0.047119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120800.jpg 162540.jpg</td>\n",
              "      <td>0.190038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200386.jpg 117646.jpg</td>\n",
              "      <td>0.116241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>268346.jpg 264478.jpg</td>\n",
              "      <td>-0.306230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171295.jpg 143107.jpg</td>\n",
              "      <td>-0.097646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       0         0\n",
              "0  262615.jpg 207587.jpg  0.047119\n",
              "1  120800.jpg 162540.jpg  0.190038\n",
              "2  200386.jpg 117646.jpg  0.116241\n",
              "3  268346.jpg 264478.jpg -0.306230\n",
              "4  171295.jpg 143107.jpg -0.097646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8pMWrV6X_lQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e7511119-424d-413b-c8fd-95c8caefd758"
      },
      "source": [
        "df.columns = ['trial','score']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trial</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262615.jpg 207587.jpg</td>\n",
              "      <td>0.047119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120800.jpg 162540.jpg</td>\n",
              "      <td>0.190038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200386.jpg 117646.jpg</td>\n",
              "      <td>0.116241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>268346.jpg 264478.jpg</td>\n",
              "      <td>-0.306230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171295.jpg 143107.jpg</td>\n",
              "      <td>-0.097646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   trial     score\n",
              "0  262615.jpg 207587.jpg  0.047119\n",
              "1  120800.jpg 162540.jpg  0.190038\n",
              "2  200386.jpg 117646.jpg  0.116241\n",
              "3  268346.jpg 264478.jpg -0.306230\n",
              "4  171295.jpg 143107.jpg -0.097646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UybGcDaFYFOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'verification.csv'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "df_csv = df.to_csv(path, index = None, header=True) #Don't forget to add '.csv' at the end of the path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnNwA9_8PXL8",
        "colab_type": "text"
      },
      "source": [
        "Some older models (for reference)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrMOwmum560W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicCNNModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BasicCNNModule, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3)\n",
        "        self.fc1 = nn.Linear(512 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = nn.Linear(60, 2300)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 512 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "        \n",
        "print(BasicCNNModule())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONOuwUJxtcOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MobileNetV1(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MobileNetV1, self).__init__()\n",
        "\n",
        "    self.layers = []\n",
        "    self.layers += self.Conv(3,32,3,1)\n",
        "    self.layers += self.DepthSepConv(32, 64, 3, 1)\n",
        "    self.layers += self.DepthSepConv(64, 128, 3, 2)       \n",
        "    self.layers += self.DepthSepConv(128, 128, 3, 1)       \n",
        "    self.layers += self.DepthSepConv(128, 256, 3, 1)    \n",
        "    self.layers += self.DepthSepConv(256, 256, 3, 1) \n",
        "    self.layers += self.DepthSepConv(256, 512, 3, 2)      \n",
        "    self.layers += self.DepthSepConv(512, 512, 3, 1)   \n",
        "    #self.layers += self.DepthSepConv(512, 512, 3, 1)      \n",
        "    #self.layers += self.DepthSepConv(512, 512, 3, 1)       \n",
        "    #self.layers += self.DepthSepConv(512, 512, 3, 1)       \n",
        "    #self.layers += self.DepthSepConv(512, 512, 3, 1)       \n",
        "    self.layers += self.DepthSepConv(512, 1024, 3, 1)     \n",
        "    self.layers += self.DepthSepConv(1024, 1024, 3, 1)    \n",
        "    self.layers.append(nn.AvgPool2d(8))\n",
        "    self.layers.append(nn.Flatten())\n",
        "    self.layers.append(nn.Linear(1024, 1000))\n",
        "    self.layers.append(nn.BatchNorm1d(1000))\n",
        "    self.layers.append(nn.ReLU(inplace = True))\n",
        "    self.layers = nn.Sequential(*self.layers)\n",
        "    \n",
        "    self.fc1 = nn.Linear(1000, 2300)\n",
        "    self.fc2 = nn.Linear(1000, 60)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    #x = x.view(-1, 1024)\n",
        "    #x = self.fc1(x)\n",
        "    #x = self.bn1(x)\n",
        "    label = self.fc1(x)\n",
        "    embedding = self.fc2(x)\n",
        "    return label, embedding\n",
        "\n",
        "  def Conv(self, c_in, c_out, k, s):\n",
        "\n",
        "      return [nn.Conv2d(c_in, c_out, k, s),\n",
        "          nn.BatchNorm2d(c_out),\n",
        "          nn.ReLU(inplace = True)]\n",
        "          \n",
        "\n",
        "  def DepthSepConv(self, c_in, c_out, k, s):\n",
        "\n",
        "      return [\n",
        "          #depth-wise\n",
        "          nn.Conv2d(c_in, c_in, k, s, 1, groups=c_in, bias=False),\n",
        "          nn.BatchNorm2d(c_in),\n",
        "          nn.ReLU(inplace=True),\n",
        "          #point-wise\n",
        "          nn.Conv2d(c_in, c_out, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(c_out),\n",
        "          nn.ReLU(inplace=True)\n",
        "      ]\n",
        "  \n",
        "  def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}